{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import of library\n",
    "#必要なライブラリのインポート\n",
    "import os\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import load_img,img_to_array\n",
    "import keras.preprocessing.image as Image\n",
    "from keras.models import Model\n",
    "from keras.datasets import fashion_mnist\n",
    "from PIL import Image\n",
    "import numpy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "import keras\n",
    "import glob\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import math\n",
    "import sys\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of variable\n",
    "#変数リスト\n",
    "#Division number\n",
    "#分割数\n",
    "cv = 10\n",
    "#research gamma\n",
    "#調べたいガンマ\n",
    "#gamma_list = np.logspace(-3, -1, 5)\n",
    "gamma_list = [0.0025,0.002,0.0015]\n",
    "\n",
    "#research nu\n",
    "#gamma_list = [0.0013,0.00131,0.00132,0.00129,0.00128\n",
    "\n",
    "#調べたいnu\n",
    "#nu_list = np.logspace(-3,-0.5,5)\n",
    "#nu = 0.000185\n",
    "\n",
    "#nuを固定する場合\n",
    "nu = 0.1\n",
    "\n",
    "#Number of test data\n",
    "#実験データの数\n",
    "data_range = 6000\n",
    "\n",
    "#その他必要な変数\n",
    "Tshirt_train = []\n",
    "shirt_train = []\n",
    "\n",
    "test = []\n",
    "\n",
    "train_label = []\n",
    "test_label = []\n",
    "\n",
    "divide = data_range//cv\n",
    "\n",
    "tmp_train = []\n",
    "tmp_test = []\n",
    "\n",
    "current_total_f_value = 0\n",
    "\n",
    "#fashion_mnistを読み込み\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images,test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntest_list = resize_array_images(train_images,48,48,img_array_list)\\ntrain = test_list[np.where(train_labels == 0)[0]]\\ntest = test_list[np.where(train_labels == 6)[0]]\\nnoise = test_list[np.where(train_labels == 2)[0]]\\n\\ntrain = np.reshape(train, (len(train),2304))\\ntest = np.reshape(test, (len(test),2304))\\nnoise = np.reshape(test, (len(noise),2304))\\n\\ntrain = train.astype('float32') / 255.0\\ntest = test.astype('float32') / 255.0\\nnoise = noise.astype('float32') / 255.0\\n\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#保存してあるデータをロード\n",
    "#0 T-シャツ/トップ (T-shirt/top)\n",
    "#1 ズボン (Trouser)\n",
    "#2 プルオーバー (Pullover)\n",
    "#3 ドレス (Dress)\n",
    "#4 コート (Coat)\n",
    "#5 サンダル (Sandal)\n",
    "#6 シャツ (Shirt)\n",
    "#7 スニーカー (Sneaker)\n",
    "#8 バッグ (Bag)\n",
    "#9 アンクルブーツ (Ankle boot)\n",
    "\n",
    "#train:学習に使うデータ\n",
    "#test:評価に使うデータ\n",
    "#noise:学習時に異常データとして混ぜるデータ\n",
    "\n",
    "#それぞれの特徴抽出の場合でデータを読み込む\n",
    "#パスは各々で指定する\n",
    "\n",
    "#HOG特徴抽出後\n",
    "train = np.load(\"/home/baba/.keras/datasets/fashion_mnist_hog_pertype/fashion_mnist_hog_0.npy\")\n",
    "test = np.load(\"/home/baba/.keras/datasets/fashion_mnist_hog_pertype/fashion_mnist_hog_6.npy\")\n",
    "noise = np.load(\"/home/baba/.keras/datasets/fashion_mnist_hog_pertype/fashion_mnist_hog_1.npy\")\n",
    "\n",
    "#VGG16特徴抽出後\n",
    "\"\"\"\n",
    "train = np.load(\"C:/Users/satok/.keras/datasets/fashion_mnist_pertype_feature/fashion_mnist_48_48_0.npy\")\n",
    "test = np.load(\"C:/Users/satok/.keras/datasets/fashion_mnist_pertype_feature/fashion_mnist_48_48_6.npy\")\n",
    "noise = np.load(\"C:/Users/satok/.keras/datasets/fashion_mnist_pertype_feature/fashion_mnist_48_48_1.npy\")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#特徴抽出前\n",
    "#train = np.load(\"C:/Users/satok/.keras/datasets/fashion_mnist_pertype/fashion_mnist_0.npy\")\n",
    "#test = np.load(\"C:/Users/satok/.keras/datasets/fashion_mnist_pertype/fashion_mnist_6.npy\")\n",
    "#noise = np.load(\"C:/Users/satok/.keras/datasets/fashion_mnist_pertype/fashion_mnist_1.npy\")\n",
    "\n",
    "\n",
    "\n",
    "#VGG16特徴抽出後にnumpy配列の形を整える\n",
    "#train = np.reshape(train, (len(train),512))\n",
    "#test = np.reshape(test, (len(test),512))\n",
    "#noise = np.reshape(test, (len(noise),512))\n",
    "\n",
    "\n",
    "#特徴抽出前のデータのnumpy配列の形を整える\n",
    "\"\"\"\n",
    "test_list = resize_array_images(train_images,48,48,img_array_list)\n",
    "train = test_list[np.where(train_labels == 0)[0]]\n",
    "test = test_list[np.where(train_labels == 6)[0]]\n",
    "noise = test_list[np.where(train_labels == 2)[0]]\n",
    "\n",
    "train = np.reshape(train, (len(train),2304))\n",
    "test = np.reshape(test, (len(test),2304))\n",
    "noise = np.reshape(test, (len(noise),2304))\n",
    "\n",
    "train = train.astype('float32') / 255.0\n",
    "test = test.astype('float32') / 255.0\n",
    "noise = noise.astype('float32') / 255.0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fashion_mnistをリサイズして返す関数\n",
    "def resize_array_images(train_images,width,height,img_array_list):\n",
    "    for i in range(len(train_images)):\n",
    "        pil_img = Image.fromarray(train_images[i])\n",
    "        pil_img = pil_img.convert(\"RGB\")\n",
    "        pil_img = pil_img.resize((width,height), Image.BICUBIC)\n",
    "        pil_img = pil_img.convert(\"L\")\n",
    "        \n",
    "        img_array = numpy.asarray(pil_img)\n",
    "        img_array_list.append(img_array)\n",
    "    img_array_list = np.array(img_array_list)\n",
    "    return img_array_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#テストデータに加えるノイズの作成\n",
    "train_noise = noise[0:divide]\n",
    "test_noise = test[0:divide]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma : 0.0025\n",
      "average_f_value : 0.8992997752434777\n",
      "\n",
      "gamma : 0.002\n",
      "average_f_value : 0.8994811916613422\n",
      "\n",
      "gamma : 0.0015\n",
      "average_f_value : 0.8993275472526487\n",
      "\n",
      "best_gamma : 0.002\n",
      "best_average_value : 0.8994811916613422\n"
     ]
    }
   ],
   "source": [
    "#grid_search and cross_validation\n",
    "current_total_f_value = 0\n",
    "best_average_f_value = 0\n",
    "#グラフ描画用\n",
    "f_value_list = []\n",
    "\n",
    "for gamma in gamma_list:\n",
    "#for nu in nu_list:\n",
    "        \n",
    "    for i in range(cv):\n",
    "        tmp_test.extend(train[i*divide: ((i+1) * divide)])\n",
    "        tmp_train.extend(train[0:i*divide])\n",
    "        tmp_train.extend(train[((i+1) * divide) : len(train)])\n",
    "        \n",
    "        tmp_train.extend(train_noise)\n",
    "        tmp_test.extend(test_noise)\n",
    "        \n",
    "        clf = svm.OneClassSVM(nu = nu, kernel=\"rbf\", gamma=gamma)\n",
    "        clf.fit(tmp_train)\n",
    "        \n",
    "        pred = clf.predict(tmp_test)\n",
    "        \n",
    "        real_true_pred = pred[0:divide]\n",
    "        real_false_pred = pred[divide : divide * 2]\n",
    "        \n",
    "        tp = len(real_true_pred[real_true_pred == 1]) / len(real_true_pred)\n",
    "        fn = len(real_true_pred[real_true_pred == -1]) / len(real_true_pred)\n",
    "        \n",
    "        fp = len(real_false_pred[real_false_pred == -1]) / len(real_false_pred)\n",
    "        tn = len(real_false_pred[real_false_pred == 1]) / len(real_false_pred)\n",
    "        \n",
    "        precision = tp/(tp + fp)\n",
    "        recall = tp/(tp + fn)\n",
    "        f_value = (2 * precision * recall) / (precision + recall)\n",
    "        \n",
    "        current_total_f_value = current_total_f_value + f_value\n",
    "        \n",
    "        tmp_test.clear()\n",
    "        tmp_train.clear()\n",
    "        \n",
    "    current_average_f_value = current_total_f_value / cv\n",
    "    \n",
    "    print(\"gamma : \" + str(gamma))\n",
    "    print(\"average_f_value : \" + str(current_average_f_value) + \"\\n\")\n",
    "    f_value_list.append(current_average_f_value)\n",
    "    \n",
    "    if(best_average_f_value < current_average_f_value):\n",
    "        best_average_f_value = current_average_f_value\n",
    "        best_gamma = gamma\n",
    "    \n",
    "    current_total_f_value = 0\n",
    "    current_average_f_value = 0\n",
    "\n",
    "print(\"best_gamma : \" + str(best_gamma))\n",
    "print(\"best_average_value : \" + str(best_average_f_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma : 0.001\n",
      "average_acc : 0.0\n",
      "\n",
      "gamma : 0.0031622776601683794\n",
      "average_acc : 0.0\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-a04670f53bab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOneClassSVM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rbf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mcurrent_total_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_total_acc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtmp_test_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/svm/classes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1119\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \"\"\"\n\u001b[0;32m-> 1121\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOneClassSVM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dense_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobA_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobB_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvm_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m             cache_size=self.cache_size)\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sparse_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#グラフを描画したい場合に実行\n",
    "plt.plot(gamma_list, f_value_list, label = \"gamma\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"gamma\")\n",
    "#対数軸にしたい場合\n",
    "plt.xscale(\"log\")\n",
    "#軸の歯にを指定したい場合\n",
    "#plt.xlim([0.053,0.057])\n",
    "#plt.ylim([0.875,0.88])\n",
    "plt.ylabel(\"f_value\")\n",
    "plt.title('Graph of searching gamma with nu=0.1')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#パラメータを決めた後、評価に使うテストデータを読み込む\n",
    "test_train = np.load(\"/home/baba/.keras/datasets/fashion_mnist_hog_pertype_test/fashion_mnist_hog_test_0.npy\")\n",
    "test_test = np.load(\"/home/baba/.keras/datasets/fashion_mnist_hog_pertype_test/fashion_mnist_hog_test_6.npy\")\n",
    "\n",
    "test_train = np.reshape(test_train, (len(test_train),900))\n",
    "test_test = np.reshape(test_test, (len(test_test),900))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#テストデータに加えるノイズの作成\n",
    "#ここのノイズデータは上のほうで使ったnoiseを使用\n",
    "train_noise = noise[0:divide]\n",
    "train_noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#学習用データの作成\n",
    "tmp_train = []\n",
    "tmp_train.extend(train)\n",
    "tmp_train.extend(train_noise)\n",
    "#評価用データの作成\n",
    "tmp_test_train = []\n",
    "tmp_test_train.extend(test_train)\n",
    "tmp_test_train.extend(test_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.002, kernel='rbf',\n",
       "      max_iter=-1, nu=0.1, random_state=None, shrinking=True, tol=0.001,\n",
       "      verbose=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#svmのモデルを作成\n",
    "svm_model = svm.OneClassSVM(nu = 0.1, kernel=\"rbf\",gamma=0.002)\n",
    "#識別関数を計算\n",
    "svm_model.fit(tmp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_value 0.9021361152508693\n"
     ]
    }
   ],
   "source": [
    "#分類、評価を行う\n",
    "pred = svm_model.predict(tmp_test_train)\n",
    "        \n",
    "real_true_pred = pred[0:1000]\n",
    "real_false_pred = pred[1000 : 2000]\n",
    "        \n",
    "tp = len(real_true_pred[real_true_pred == 1]) / len(real_true_pred)\n",
    "fn = len(real_true_pred[real_true_pred == -1]) / len(real_true_pred)\n",
    "        \n",
    "fp = len(real_false_pred[real_false_pred == -1]) / len(real_false_pred)\n",
    "tn = len(real_false_pred[real_false_pred == 1]) / len(real_false_pred)\n",
    "        \n",
    "precision = tp/(tp + fp)\n",
    "recall = tp/(tp + fn)\n",
    "f_value = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"f_value \" + str(f_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#以下,HOG特徴量で画像を保存する場合\n",
    "\n",
    "#ファイル内のjpg画像を一括読み込みする関数\n",
    "def fileRead():\n",
    "    data = []\n",
    "    for file in glob.glob(\"/home/baba/.keras/datasets/fashion-mnist-test-images/*.jpg\"):\n",
    "        data.append( cv2.imread(file, 0) )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ファイルから画像を読み込む準備\n",
    "img = cv2.imread(\"/home/baba/.keras/datasets/fashion-mnist-images/fashion_mnist_BICUBIC00000.jpg\",0)\n",
    "cv2.imshow(\"image\",img)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#読み込み\n",
    "data = fileRead()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HOGのパラメータ決定\n",
    "#基本的にはこれでいい\n",
    "#winsizeは画像のサイズ\n",
    "hog_train = []\n",
    "winsize = (48,48)\n",
    "block_size = (16,16)\n",
    "block_stride = (8,8)\n",
    "cell_size = (8,8)\n",
    "nbins = 9\n",
    "\n",
    "hog = cv2.HOGDescriptor(winsize,block_size,block_stride,cell_size,nbins)\n",
    "for filepath in data:\n",
    "    hog_train.append(hog.compute(filepath))\n",
    "\n",
    "hog_train = np.array(hog_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 900, 1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hog_train.shape\n",
    "hog_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svmで分類できるように形を整える\n",
    "hog_train = np.reshape(hog_train, (len(hog_train),900))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 900)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hog_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = hog_train[np.where(test_labels == 0)[0]]\n",
    "test = hog_train[np.where(test_labels == 6)[0]]\n",
    "noise = hog_train[np.where(test_labels == 1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(\"/home/baba/.keras/datasets/fashion_mnist_hog_pertype_test/\" , \"fashion_mnist_hog_test_1.npy\"),noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
