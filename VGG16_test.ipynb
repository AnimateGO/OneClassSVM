{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#必要なライブラリをインポート\n",
    "import os\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import load_img,img_to_array\n",
    "import keras.preprocessing.image as Image\n",
    "from keras.models import Model\n",
    "from keras.datasets import fashion_mnist\n",
    "from PIL import Image\n",
    "import numpy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "import keras\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG16のモデル設定\n",
    "base_model = VGG16(include_top=False, \n",
    "                   weights='imagenet',\n",
    "                  input_shape = (48,48,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fashion_mnistを読み込み\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#npyで保存\n",
    "np.save(os.path.join(\"/home/baba/.keras/datasets/\" , \"fashion_mnist_test.npy\"),train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#画像を読み込んでnumpy形式に変換\n",
    "#VGG16に入力できるように整形（データの番号,縦,横,3）\n",
    "#パスは適宜変更する\n",
    "img = image.load_img(\"/home/baba/test_VGG16/gnct_symbol.jpg\",\n",
    "                    target_size = (224,224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x,axis = 0)\n",
    "x = x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#原型\n",
    "#(縦,横)の形にnumpy配列を整形\n",
    "test = x_test_1[108].reshape(28,28)\n",
    "\n",
    "#変形したnumpy配列をpilでリサイズして保存\n",
    "#saveは（保存するフォルダのパス , 保存したいファイルの名前.拡張子）\n",
    "pil_img = Image.fromarray(test)\n",
    "pil_img = pil_img.convert(\"RGB\")\n",
    "pil_img = pil_img.resize((224,224))\n",
    "pil_img.save(os.path.join(\"/home/baba/test_VGG16/\", 'mnist_test.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#テスト用\n",
    "test = train_images[0].reshape(28,28)\n",
    "test.shape\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_img = Image.fromarray(test)\n",
    "pil_img = pil_img.convert(\"RGB\")\n",
    "pil_img = pil_img.resize((224,224))\n",
    "pil_img.save(os.path.join(\"/home/baba/.keras/datasets/\" , \"fashion_mnist_NEAREST\"+\"%05.f\"%(i)+\".jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#画像を保存せずにできるようにするテスト\n",
    "#train_imageから10個結合する\n",
    "img_array_list = []\n",
    "\n",
    "for i in range(10):\n",
    "    piltest_img = Image.fromarray(train_images[i])\n",
    "    piltest_img = piltest_img.convert(\"RGB\")\n",
    "    piltest_img = piltest_img.resize((224,224), Image.BICUBIC)\n",
    "    \n",
    "    img_array = numpy.asarray(piltest_img)\n",
    "    img_array_list.append(img_array)\n",
    "img_array_list = np.array(img_array_list)\n",
    "img_array_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array_list = []\n",
    "\n",
    "for i in range(len(train_images)):\n",
    "    piltest_img = Image.fromarray(train_images[i])\n",
    "    piltest_img = piltest_img.convert(\"RGB\")\n",
    "    piltest_img = piltest_img.resize((48,48), Image.BICUBIC)\n",
    "    \n",
    "    img_array = numpy.asarray(piltest_img)\n",
    "    img_array_list.append(img_array)\n",
    "img_array_list = np.array(img_array_list)\n",
    "img_array_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fashion_mnistをリサイズして返す関数#\n",
    "def resize_array_images(train_images,width,height,img_array_list):\n",
    "    for i in range(len(train_images)):\n",
    "        pil_img = Image.fromarray(train_images[i])\n",
    "        pil_img = pil_img.convert(\"RGB\")\n",
    "        pil_img = pil_img .resize((width,height), Image.BICUBIC)\n",
    "        \n",
    "        img_array = numpy.asarray(pil_img)\n",
    "        img_array_list.append(img_array)\n",
    "    img_array_list = np.array(img_array_list)\n",
    "    return img_array_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array_list = img_array_list/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(\"/home/baba/.keras/datasets\" , \"fashion_mnist_48_48_BICUBIC.npy\"),img_array_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 1, 512)\n"
     ]
    }
   ],
   "source": [
    "bottleneck_features_train = base_model.predict(img_array_list)\n",
    "print(bottleneck_features_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(\"/home/baba/.keras/datasets\" , \"fashion_mnist_bottleneck_48_48.npy\"),bottleneck_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fashion_mnistのtrainデータを画像で保存(60000個でだいたい234MB)\n",
    "for i in range(len(train_images)):\n",
    "    reshape_numpy_image = train_images[i].reshape(28,28)\n",
    "    \n",
    "    pil_img = Image.fromarray(reshape_numpy_image)\n",
    "    pil_img = pil_img.convert(\"RGB\")\n",
    "    pil_img = pil_img.resize((48,48), Image.BICUBIC)\n",
    "    pil_img.save(os.path.join(\"/home/baba/.keras/datasets/fashion-mnist-images/\" , \"fashion_mnist_BICUBIC\"+\"%05.f\"%(i)+\".jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#グレースケールの画像をカラー画像の形式に変換\n",
    "#transposeは行列の転置などを使うが、正直意味はよく理解していないので要確認\n",
    "\n",
    "img_width = 48\n",
    "img_height = 48\n",
    "def gray_to_rgb(X):\n",
    "    X_transpose = np.array(X.transpose(0, 2, 3, 1))\n",
    "    ret = np.empty((X.shape[0], img_width, img_height, 3), dtype=np.float32)\n",
    "    ret[:, :, :, 0] = X_transpose[:, :, :, 0]\n",
    "    ret[:, :, :, 1] = X_transpose[:, :, :, 0]\n",
    "    ret[:, :, :, 2] = X_transpose[:, :, :, 0]\n",
    "    return ret.transpose(0, 1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 3)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gray_to_rgb(train_images)\n",
    "reshape_numpy_image = train_images.reshape(60000,28,28,1)\n",
    "a = gray_to_rgb(reshape_numpy_image)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image  array size\n",
    "img_size = (48,48)\n",
    "#load images Folder\n",
    "dir_name = 'fashion-mnist-images'\n",
    "#File type\n",
    "file_type  = 'jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load images and image to array\n",
    "img_list = sorted(glob.glob('/home/baba/.keras/datasets/' + dir_name + '/*.' + file_type))\n",
    "temp_img_array_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "temp_img = load_img(img_list[1],grayscale=False,target_size=(img_size))\n",
    "temp_img_array = img_to_array(temp_img)\n",
    "temp_img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d1eba4309fce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtemp_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrayscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtemp_img_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_img\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtemp_img_array_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_img_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "#img_listに読み込んだ画像ファイルを読み込んで、numpy配列にして結合\n",
    "for img in img_list:\n",
    "    temp_img = load_img(img,grayscale=False,target_size=(img_size))\n",
    "    temp_img_array = img_to_array(temp_img) /255\n",
    "    temp_img_array_list.append(temp_img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 48, 48, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_img_array_list = np.array(temp_img_array_list)\n",
    "temp_img_array_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "np.save(\"/home/baba/.keras/datasets/fashion_mnist_images.npy\",temp_img_array_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example pick mnist array\n",
    "def converter(xarray, yarray, num, outputnum):\n",
    "\t#numで指定されたラベルの値の該当するデータを抽出し，成形する\n",
    "\txarray = xarray[np.where(yarray == num)[0]]\n",
    "\txarray = xarray.astype('float32') / 255.0\n",
    "\txarray = np.reshape(xarray, (len(xarray),outputnum))\n",
    "\treturn xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 28, 28)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#以降、fashion_mnistの中身を取り出して保存するコード\n",
    "#resize_array_imagesは関数\n",
    "fashion_mnist_type = test_images[np.where(test_labels == 9)[0]]\n",
    "fashion_mnist_type.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 48, 48, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array_list = []\n",
    "fashion_mnist_pertype = resize_array_images(fashion_mnist_type,48,48,img_array_list)\n",
    "fashion_mnist_pertype.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"C:/Users/satok/.keras/datasets/fashion_mnist_pertype_test/fashion_mnist_test_9.npy\",fashion_mnist_pertype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 48, 48, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_9 = np.load(\"C:/Users/satok/.keras/datasets/fashion_mnist_pertype_test/fashion_mnist_test_9.npy\")\n",
    "img_9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1, 1, 512)\n"
     ]
    }
   ],
   "source": [
    "img_9 = img_9/255\n",
    "bottleneck_features_train = base_model.predict(img_9)\n",
    "print(bottleneck_features_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"C:/Users/satok/.keras/datasets/fashion_mnist_pertype_feature_test/fashion_mnist_test_9.npy\",bottleneck_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
